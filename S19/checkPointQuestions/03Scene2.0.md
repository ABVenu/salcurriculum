**Scene 2.0**

### **Which component of an LLM is responsible for breaking down input text into smaller units like words or subwords?**

A) Embedding layer  
B) Transformer architecture  
C) Tokenization  
D) Output Prediction

**Answer:** C) Tokenization

---

### **In the context of LLMs, what do "parameters" represent?**

A) The hardware specifications of the computer running the model  
B) The specific programming language used to build the model  
C) The knowledge and patterns a model learns during its training phase  
D) The number of times a model has been used for inference

**Answer:** C) The knowledge and patterns a model learns during its training phase

---

### **What does "Inference" refer to in AI?**

A) The process of training an AI model from scratch  
B) The act of using a trained AI model to make predictions or generate answers  
C) The initial data collection phase for an AI project  
D) The method of debugging an AI algorithm

**Answer:** B) The act of using a trained AI model to make predictions or generate answers

---

### **If you want an AI model to generate more creative and varied outputs, what setting would you typically increase?**

A) Parameters  
B) Temperature  
C) Number of hidden layers  
D) Tokenization limit

**Answer:** B) Temperature

---

### **What is a "hallucination" in the context of AI?**

A) When an AI model generates highly imaginative and artistic content  
B) When an AI model provides a confident answer that is factually incorrect or made up  
C) When an AI model struggles to process visual data  
D) When an AI model experiences a software error

**Answer:** B) When an AI model provides a confident answer that is factually incorrect or made up

---

